---
title: "Week 4: Classification"
output: html_notebook
---

# import the data

```{r}

gc <- read.csv("german_credit.csv")



```

# check the data

```{r}
head(gc)
```

# understanding data structure

```{r}
str(gc)
```

# Feature / Attribute Selection

# The variable 'Credibility' is out target variable i.e. this variable will determine whether the bank manager will approve a loan based on the 7 Attributes.

```{r}
gc.subset <- gc[c('Creditability', 'Age..years.', 'Sex...Marital.Status', 'Occupation', 'Account.Balance', 'Credit.Amount', 'Length.of.current.employment', 'Purpose')]

head(gc.subset)
```

# Data normalization to avoid biasness as the value scale of 'Credit.Amount' is in thousands whereas other attributes value are in 2 digit or 1 digit.

```{r}

normalize <- function(x) {
  return((x - min(x)) / (max(x) - min(x))) # creating a normalize function for easy conversion
}

gc.subset.n <- as.data.frame(lapply(gc.subset[,2:8], normalize)) # lapply creates a list that is why it is converted to a dataframe and it applies the defined function (which is 'normalize') to all the list values which is here column 2 to 8 as first column is target/response.

head(gc.subset.n)
```

# Creating Training and Test data set

```{r}
set.seed(123) # To get the same random sample

dat.d <- sample(1:nrow(gc.subset.n), size = nrow(gc.subset.n) * 0.7, replace = FALSE) # Random selection of 70% data.

train.gc <- gc.subset[dat.d,] # 70% training data
test.gc <- gc.subset[-dat.d,] # remaining 30% test data

# Now creating separate dataframe for 'Credibility' feature which is our target.

train.gc_labels <- gc.subset[dat.d, 1]
test.gc_labels <- gc.subset[-dat.d, 1]

```

# Training the model

```{r}
library(class)

NROW(train.gc_labels) # to find number of observations

# To identify optimum value of k, generally square root of total no of observations (700) which is 26.45 is taken, so will try with 26, 27 and then will check for optimal value of k.

knn.26 <- knn(train = train.gc, test = test.gc, cl = train.gc_labels, k = 26)

knn.27 <- knn(train = train.gc, test = test.gc, cl = train.gc_labels, k = 27)
  
  
```

# Evaluate model performance

```{r}

ACC.26 <- 100 * sum(test.gc_labels == knn.26) / NROW(test.gc_labels) # for knn = 26

ACC.27 <- 100 * sum(test.gc_labels == knn.27) / NROW(test.gc_labels) # for knn = 27

ACC.26 

ACC.27 # At 69 is most accurate (Uni Lab papers were worng .. cough.. cough...)

table(knn.26, test.gc_labels) # to check prediction against actual value in tabular form


table(knn.27, test.gc_labels)

```
Accuracy can also be calculated using the 'caret' package and 'confusion matrix' function

```{r}
# For knn.26

library(caret)

test.gc_labels <- as.factor(test.gc_labels)
confusionMatrix(knn.26, test.gc_labels)

## Confusion matrix and statistics
```

```{r}
# For knn.27

test.gc_labels <- as.factor(test.gc_labels)
confusionMatrix(knn.27, test.gc_labels)

```

# Improve the model

