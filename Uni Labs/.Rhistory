na_count10 <- sum(is.na(aero$Fatalities))
na_count1
na_count2
na_count3
na_count4
na_count5
na_count6
na_count7
na_count8
na_count9
na_count10
str(aero$Date)
str(aero$Time)
str(aero$Location)
str(aero$Operator)
str(aero$Route)
str(aero$type)
str(aero$Registration)
str(aero$cn.In)
str(aero$Aboard)
str(aero$Fatalities)
str(aero$Date)
str(aero$Time)
str(aero$Location)
str(aero$Operator)
str(aero$Route)
str(aero$type)
str(aero$Registration)
str(aero$cn.In)
str(aero$Aboard)
str(aero$Fatalities)
str(aero$Ground)
str(aero$Summary)
aero$Date <- as.Date(aero$Date, format="%m/%d/%Y") # Change Date from a char to Date data type
aero$Time <- lubridate::hm(aero$Time) # Change from char to lubridate
aero$Location <- ifelse(aero$Location == "", NA, aero$Location)
aero$Operator <- ifelse(aero$Operator == "", NA, aero$Operator)
aero$Flight.. <- ifelse(aero$Flight.. == "", NA, aero$Flight..)
aero$Flight.. <- ifelse(aero$Flight.. == "-", NA, aero$Flight..)
aero$Route <- ifelse(aero$Route == "", NA, aero$Route)
aero$Type <- ifelse(aero$Type == "", NA, aero$Type)
aero$Registration <- ifelse(aero$Registration == "", NA, aero$Registration)
aero$cn.In <- ifelse(aero$cn.In == "", NA, aero$cn.In)
aero$Summary <- ifelse(aero$Summary == "", NA, aero$Summary)
#install.packages("readr")
library(readr)
library(lubridate)
aero <- read.csv("Airplane_Crashes_and_Fatalities_Since_1908.csv")
str(aero$Date)
str(aero$Time)
str(aero$Location)
str(aero$Operator)
str(aero$Route)
str(aero$type)
str(aero$Registration)
str(aero$cn.In)
str(aero$Aboard)
str(aero$Fatalities)
str(aero$Ground)
str(aero$Summary)
aero$Date <- as.Date(aero$Date, format="%m/%d/%Y") # Change Date from a char to Date data type
aero$Time <- lubridate::hm(aero$Time) # Change from char to lubridate
aero$Location <- ifelse(aero$Location == "", NA, aero$Location)
aero$Operator <- ifelse(aero$Operator == "", NA, aero$Operator)
aero$Flight.. <- ifelse(aero$Flight.. == "", NA, aero$Flight..)
aero$Flight.. <- ifelse(aero$Flight.. == "-", NA, aero$Flight..)
aero$Route <- ifelse(aero$Route == "", NA, aero$Route)
aero$Type <- ifelse(aero$Type == "", NA, aero$Type)
aero$Registration <- ifelse(aero$Registration == "", NA, aero$Registration)
aero$cn.In <- ifelse(aero$cn.In == "", NA, aero$cn.In)
aero$Summary <- ifelse(aero$Summary == "", NA, aero$Summary)
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
round(misscol, 2)
na_count1 <- sum(is.na(aero$Date))
na_count2 <- sum(is.na(aero$Time))
na_count3 <- sum(is.na(aero$Operator))
na_count4 <- sum(is.na(aero$Flight..))
na_count5 <- sum(is.na(aero$Route))
na_count6 <- sum(is.na(aero$Type))
na_count7 <- sum(is.na(aero$Registration))
na_count8 <- sum(is.na(aero$cn.In))
na_count9 <- sum(is.na(aero$Aboard))
na_count10 <- sum(is.na(aero$Fatalities))
na_count11 <- sum(is.na(aero$Ground))
na_count12 <- sum(is.na(aero$Summary))
na_count1
na_count2
na_count3
na_count4
na_count5
na_count6
na_count7
na_count8
na_count9
na_count10
na_count11
na_count12
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
round(misscol, 2)
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
#round(misscol, 2)
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
#round(misscol, 2)
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
misscol
#round(misscol, 2)
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
round(misscol, 2)
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
round(misscol, 3)
na_count1 <- sum(is.na(aero$Date))
na_count2 <- sum(is.na(aero$Time))
na_count3 <- sum(is.na(aero$Operator))
na_count4 <- sum(is.na(aero$Flight..))
na_count5 <- sum(is.na(aero$Route))
na_count6 <- sum(is.na(aero$Type))
na_count7 <- sum(is.na(aero$Registration))
na_count8 <- sum(is.na(aero$cn.In))
na_count9 <- sum(is.na(aero$Aboard))
na_count10 <- sum(is.na(aero$Fatalities))
na_count11 <- sum(is.na(aero$Ground))
na_count12 <- sum(is.na(aero$Summary))
na_count1
na_count2
na_count3
na_count4
na_count5
na_count6
na_count7
na_count8
na_count9
na_count10
na_count11
na_count12
unique(aero$Route)
unique(aero$Route).sum()
p <- unique(aero$Route)
sum(p)
p <- unique(aero$Registration)
unique(aero$Registration)
library(tidytext)
install.packages("tidytext")
#install.packages("readr")
library(readr)
library(lubridate)
aero <- read.csv("Airplane_Crashes_and_Fatalities_Since_1908.csv")
str(aero$Date)
str(aero$Time)
str(aero$Location)
str(aero$Operator)
str(aero$Route)
str(aero$type)
str(aero$Registration)
str(aero$cn.In)
str(aero$Aboard)
str(aero$Fatalities)
str(aero$Ground)
str(aero$Summary)
#install.packages("readr")
library(readr)
library(lubridate)
aero <- read.csv("Airplane_Crashes_and_Fatalities_Since_1908.csv")
aero$Date <- as.Date(aero$Date, format="%m/%d/%Y") # Change Date from a char to Date data type
aero$Time <- lubridate::hm(aero$Time) # Change from char to lubridate
aero$Location <- ifelse(aero$Location == "", NA, aero$Location)
aero$Operator <- ifelse(aero$Operator == "", NA, aero$Operator)
aero$Flight.. <- ifelse(aero$Flight.. == "", NA, aero$Flight..)
aero$Flight.. <- ifelse(aero$Flight.. == "-", NA, aero$Flight..)
aero$Route <- ifelse(aero$Route == "", NA, aero$Route)
aero$Type <- ifelse(aero$Type == "", NA, aero$Type)
aero$Registration <- ifelse(aero$Registration == "", NA, aero$Registration)
aero$cn.In <- ifelse(aero$cn.In == "", NA, aero$cn.In)
aero$Summary <- ifelse(aero$Summary == "", NA, aero$Summary)
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#aero$Date[aero$Date == ""] <- NA # Fill in empty string with NA
#print(aero$Date)
#print(aero$Time)
misscol <- colSums(is.na(aero)) / nrow(aero)
round(misscol, 3)
na_count1 <- sum(is.na(aero$Date))
na_count2 <- sum(is.na(aero$Time))
na_count3 <- sum(is.na(aero$Operator))
na_count4 <- sum(is.na(aero$Flight..))
na_count5 <- sum(is.na(aero$Route))
na_count6 <- sum(is.na(aero$Type))
na_count7 <- sum(is.na(aero$Registration))
na_count8 <- sum(is.na(aero$cn.In))
na_count9 <- sum(is.na(aero$Aboard))
na_count10 <- sum(is.na(aero$Fatalities))
na_count11 <- sum(is.na(aero$Ground))
na_count12 <- sum(is.na(aero$Summary))
na_count1
na_count2
na_count3
na_count4
na_count5
na_count6
na_count7
na_count8
na_count9
na_count10
na_count11
na_count12
#install.packages("readr")
library(readr)
library(lubridate)
aero <- read.csv("Airplane_Crashes_and_Fatalities_Since_1908.csv")
aero$Date <- as.Date(aero$Date, format="%m/%d/%Y") # Change Date from a char to Date data type
aero$Time <- lubridate::hm(aero$Time) # Change from char to lubridate
aero$Location <- ifelse(aero$Location == "", NA, aero$Location)
aero$Operator <- ifelse(aero$Operator == "", NA, aero$Operator)
aero$Flight.. <- ifelse(aero$Flight.. == "", NA, aero$Flight..)
aero$Flight.. <- ifelse(aero$Flight.. == "-", NA, aero$Flight..)
aero$Route <- ifelse(aero$Route == "", NA, aero$Route)
aero$Type <- ifelse(aero$Type == "", NA, aero$Type)
aero$Registration <- ifelse(aero$Registration == "", NA, aero$Registration)
aero$cn.In <- ifelse(aero$cn.In == "", NA, aero$cn.In)
aero$Summary <- ifelse(aero$Summary == "", NA, aero$Summary)
library(tidytext)
install.packages("tidytext")
install.packages(c("clock", "ipred", "missRanger", "Rcpp", "SparseM", "tinytex", "xfun"))
install.packages("tidytext")
library(tidytext)
#install.packages("readr")
library(readr)
library(lubridate)
aero <- read.csv("Airplane_Crashes_and_Fatalities_Since_1908.csv")
aero$Date <- as.Date(aero$Date, format="%m/%d/%Y") # Change Date from a char to Date data type
aero$Time <- lubridate::hm(aero$Time) # Change from char to lubridate
aero$Location <- ifelse(aero$Location == "", NA, aero$Location)
aero$Operator <- ifelse(aero$Operator == "", NA, aero$Operator)
aero$Flight.. <- ifelse(aero$Flight.. == "", NA, aero$Flight..)
aero$Flight.. <- ifelse(aero$Flight.. == "-", NA, aero$Flight..)
aero$Route <- ifelse(aero$Route == "", NA, aero$Route)
aero$Type <- ifelse(aero$Type == "", NA, aero$Type)
aero$Registration <- ifelse(aero$Registration == "", NA, aero$Registration)
aero$cn.In <- ifelse(aero$cn.In == "", NA, aero$cn.In)
aero$Summary <- ifelse(aero$Summary == "", NA, aero$Summary)
library(tidytext)
library(dplyr)
word_counts <- aero$Summary %>% #
unnest_tokens(word, text) %>%  # This function splits the text into individual words.
count(word, sort = TRUE)       # This function counts the occurrences of each word and sorts them in descending order.
library(tidytext)
library(dplyr)
word_counts <- aero$Summary %>% #
unnest_tokens(word, text) %>%  # This function splits the text into individual words.
count(word, sort = TRUE)       # This function counts the occurrences of each word and sorts them in descending order.
library(tidytext)
library(dplyr)
aero <- as_tibble(aero)
# Tokenize and count words
word_counts <- aero %>%
unnest_tokens(word, Summary) %>%  # Ensure the column name matches
count(word, sort = TRUE)          # Count occurrences of each word
print(word_counts)
gc <- read.csv("german_credit.csv")
gc <- read.csv("german_credit.csv")
head(gc)
str(gc)
gc.subset <- gc[c('Creditability', 'Age..years', 'Sex...Marital.Status', 'Occupation', 'Account.Balance', 'Credit.Amount', 'Length.of.current.employment', 'Purpose')]
View(gc)
gc.subset <- gc[c('Creditability', 'Age..years.', 'Sex...Marital.Status', 'Occupation', 'Account.Balance', 'Credit.Amount', 'Length.of.current.employment', 'Purpose')]
head(gc.subset)
normalize < function(x) {
return((x - min(x)) / (max(x) - min(x))) # creating a normalize function for easy conversion
}
normalize < function(x) {
return((x - min(x)) / (max(x) - min(x))) # creating a normalize function for easy conversion
}
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x))) # creating a normalize function for easy conversion
}
gc.subset.n <- as.data.frame(lapply(gc.subset[,2:8], normalize))
head(gc.subset.n)
set.seed(123) # To get the same random sample
dat.d <- sample(1:nrow(gc.subset.n), size = nrow(gc.subset.n) * 0.7, replace = FALSE) # Random selection of 70% data.
train.gc <- gc.subset[dat.d,] # 70% training data
test.gc <- gc.subset[~ dat.d,] # remaining 30% test data
set.seed(123) # To get the same random sample
dat.d <- sample(1:nrow(gc.subset.n), size = nrow(gc.subset.n) * 0.7, replace = FALSE) # Random selection of 70% data.
train.gc <- gc.subset[dat.d,] # 70% training data
test.gc <- gc.subset[~dat.d,] # remaining 30% test data
set.seed(123) # To get the same random sample
dat.d <- sample(1:nrow(gc.subset.n), size = nrow(gc.subset.n) * 0.7, replace = FALSE) # Random selection of 70% data.
train.gc <- gc.subset[dat.d,] # 70% training data
test.gc <- gc.subset[- dat.d,] # remaining 30% test data
# Now creating separate dataframe for 'Credibility' feature which is our target.
train.gc_labels <- gc.subset[dat.d, 1]
test.gc_labels <- gc.subset[~ dat.d, 1]
set.seed(123) # To get the same random sample
dat.d <- sample(1:nrow(gc.subset.n), size = nrow(gc.subset.n) * 0.7, replace = FALSE) # Random selection of 70% data.
train.gc <- gc.subset[dat.d,] # 70% training data
test.gc <- gc.subset[-dat.d,] # remaining 30% test data
# Now creating separate dataframe for 'Credibility' feature which is our target.
train.gc_labels <- gc.subset[dat.d, 1]
test.gc_labels <- gc.subset[-dat.d, 1]
library(class)
NROW(train.gc_labels) # to find number of observations
library(class)
NROW(train.gc_labels) # to find number of observations
# To identify optimum value of k, generally square root of total no of observations (700) which is 26.45 is taken, so will try with 26, 27 and then will check for optimal value of k.
knn.26 <- knn(train = train.gc, test = test.gc, cl = train.gc_labels, k = 26)
knn.27 <- knn(train = train.gc, test = test.gc, cl = train.gc_labels, k = 27)
ACC.26 <- 100 * sum(test.gc_labels == knn.26) / NROW(test.gc_labels) # for knn = 26
ACC.27 <- 100 * sum(test.gc_labels == knn.27) / NROW(test.gc_labels) # for knn = 27
AAC.26
ACC.26 <- 100 * sum(test.gc_labels == knn.26) / NROW(test.gc_labels) # for knn = 26
ACC.27 <- 100 * sum(test.gc_labels == knn.27) / NROW(test.gc_labels) # for knn = 27
ACC.26
ACC.27
ACC.26 <- 100 * sum(test.gc_labels == knn.26) / NROW(test.gc_labels) # for knn = 26
ACC.27 <- 100 * sum(test.gc_labels == knn.27) / NROW(test.gc_labels) # for knn = 27
ACC.26
ACC.27 # At 69 is most accurate (Uni Lab papers were worng .. cough.. cough...)
table(knn.26, test.gc_labels) # to check prediction against actual value in tabular form
ACC.26 <- 100 * sum(test.gc_labels == knn.26) / NROW(test.gc_labels) # for knn = 26
ACC.27 <- 100 * sum(test.gc_labels == knn.27) / NROW(test.gc_labels) # for knn = 27
ACC.26
ACC.27 # At 69 is most accurate (Uni Lab papers were worng .. cough.. cough...)
table(knn.26, test.gc_labels) # to check prediction against actual value in tabular form
table(knn.27, test.gc_labels)
library(caret)
test.gc_labels <- as.factor(test.gc_labels)
confusionMatrix(knn.26, test.gc_labels)
## Confusion matrix and statistics
# For knn.27
test.gc_labels <- as.factor(test.gc_labels)
confusionMatrix(knn.27, test.gc_labels)
i=1 # declaration for infinite for loop
k.optm = 1 # declaration for infinite for loop
for (i in 1:128) {
knn.mod <- knn(train = train.gc, test = test.gc, cl = train.gc_labels, k = i)
k.optm[i] <- 100 * sum(test.gc_labels == knn.mod) / NROW(test.gc_labels)
k = i
cat(k, '=', k.optm[i], '\n') # to print % accuracy
}
i=1 # declaration for infinite for loop
k.optm = 1 # declaration for infinite for loop
for (i in 1:128) {
knn.mod <- knn(train = train.gc, test = test.gc, cl = train.gc_labels, k = i)
k.optm[i] <- 100 * sum(test.gc_labels == knn.mod) / NROW(test.gc_labels)
k = i
cat(k, '=', k.optm[i], '\n') # to print % accuracy
}
plot(k.optm, type = "b", xlab = "K-Value", ylab = "Accuracy level") # to plot % accuracy to k-value
df <- data(iris) ## load data
head(iris) ## see the structure
## Generate a random number that is 90% of the total number of rows in the dataset.
ran <- sample(1:nrow(iris),0.9 * nrow(iris))
## The normalization function is created
nor <-function(x) {
(x -min(x) / (max(x) - min(x)))
}
# Run the normalization on first 4 columns of dataset because they are the predictors
iris_norm <- as.data.frame(lapply(iris[c(1,2,3,4)], nor))
# Extract training set
iris_train <- iris_norm[ran,]
# Extract testing set
iris_test <- iris_norm[-ran,]
iris_target_category <- iris[ran, 5] # extract 5th column of train dataset because it will be used as 'cl' argument in k-nn function
iris_test_category <- iris[-ran, 5] # extract 5th column of test dataset to measure the accuracy
library(class)
pr <- knn(iris_train, iris_test, cl = iris_target_category, k =13)
## Create confusion matrix
tab <- table(pr, iris_test_category)
# this function divides the correct predictions by total number of predictions that tell us how accurate the model is.
accuracy <- function(x) {
sum(diag(x) / sum(rowSums(x))) * 100
}
accuracy(tab)
# Because diamonds dataset is in ggplot2 package
library(ggplot2)
data(diamonds)
dia <- data.frame(diamonds) # Store as a data frame
ran <- sample(1:nrow(dia), 0.9 * nrow(dia)) # create a random number equal 90% of total number of rows
#the normalization function is created
nor <- function(x) {
(x -min(x)) / (max(x) -min(x))
}
dia_nor <- as.data.frame(lapply(dia[,c(1,5,6,7,8,9,10)], nor))
# training dataset extracted
dia_train <- dia_nor[ran, ]
# test dataset extracted
dia_test <- dia_nor[-ran,]
dia_target <- as.factor(dia[ran,2])
test_target <- as.factor(dia[-ran, 2])
# run knn functions
library(class)
pr <- knn(dia_train, dia_test, cl = dia_target, k = 20)
# create the confusion matrix
tb <- table(pr, test_target)
# Check accuracy
accuracy <- function(x) {
sum(diag(x) / (sum(rowSums(x)))) * 100
}
accuracy(tb)
prc <- read.csv(Prostate_Cancer.csv)
setwd("~/GitHub/Data-Science-and-Machine-Learning-with-R-from-A-Z-Course")
prc <- read.csv(Prostate_Cancer.csv)
setwd("~/GitHub/Data-Science-and-Machine-Learning-with-R-from-A-Z-Course/Uni Labs")
prc <- read.csv(Prostate_Cancer.csv)
prc <- read.csv(Prostate_Cancer.csv)
prc <- read.csv(Prostate_Cancer.csv)
setwd("~/GitHub/Data-Science-and-Machine-Learning-with-R-from-A-Z-Course/Uni Labs")
prc <- read.csv(Prostate_Cancer.csv)
prc <- read.csv(Prostate_Cancer.csv)
prc <- read.csv(Prostate_Cancer.csv)
prc <- read.csv(Prostate_Cancer.csv)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
setwd("~/GitHub/Data-Science-and-Machine-Learning-with-R-from-A-Z-Course/Uni Labs")
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv(Prostate_Cancer.csv)
library(readr)
prc <- read.csv("Prostate_Cancer.csv")
# import the data
library(readr)
prc <- read.csv("Prostate_Cancer.csv", stringsAsFactors = FALSE)
# import the data
library(readr)
prc <- read.csv("Prostate_Cancer.csv", stringsAsFactors = FALSE) # imports data and converts every chat to a factor wherever it makes sense
str(prc)
prc <- prc[-1] # removed the first variable (column) from the dataset (id)
table(prc$diagnosis_result) # it helps us to get number of patients
table(prc$diagnosis_result) # it helps us to get number of patients with B & M
prc$diagnosis_result <- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
round(prop.table(table(prc$diagnosis_result)) * 100, digits - 1)
prc$diagnosis_result <- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
round(prop.table(table(prc$diagnosis_result)) * 100, digits = 1)
prc$diagnosis_result <- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
round(prop.table(table(prc$diagnosis_result)) * 100, digits = 1)
prc$diagnosis_result <- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
round(prop.table(table(prc$diagnosis_result)) * 100, digits = 1)
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
prc_n <- as.data.frame(lapply(prc[2:9], normalize))
View(prc)
View(prc_n)
View(prc)
# import the data
library(readr)
prc <- read.csv("Prostate_Cancer.csv", stringsAsFactors = FALSE) # imports data and converts every chat to a factor wherever it makes sense
str(prc)
prc <- prc[-1] # removed the first variable (column) from the dataset (id)
prc$diagnosis_result <- factor(prc$diagnosis_result, levels = c("B", "M"), labels = c("Benign", "Malignant"))
round(prop.table(table(prc$diagnosis_result)) * 100, digits = 1)
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
prc_n <- as.data.frame(lapply(prc[2:9], normalize))
View(prc)
summary(prc$radius)
View(prc_n)
summary(prc_n$radius)
prc_train <- prc_n[1:65,]
prc_test <- prc_n[66:100,]
prc_train_labels <- prc[1:65, 1] # Include diagnosis_factor to label the data
prc_test_labels <- prc[66:100, 1]
library(class)
prc_test_pred <- knn(train = prc_train, test = prc_test, cl = prc_train_labels, k =10) # k = square root of num of observations
library(gmodels)
install.packages("gmodels")
library(gmodels)
library(gmodels)
CrossTable(x = prc_test_labels, y = prc_test_pred, prop.chisq = FALSE)
